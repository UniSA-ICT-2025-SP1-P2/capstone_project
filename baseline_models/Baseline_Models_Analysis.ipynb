{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18089937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import os\n",
    "import shap\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n",
    "                             roc_auc_score, classification_report, confusion_matrix)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3655eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github directory to retrieve dataset:\n",
    "df = pd.read_csv('../data/CIC-MalMem2022.csv')\n",
    "\n",
    "# Fill the missing values:\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "\n",
    "# Functions to extract unique files and records for each category:\n",
    "def find_category(file_name):\n",
    "    if \"-\" in file_name:\n",
    "        return file_name.split(\"-\")[0]\n",
    "    else:\n",
    "        return file_name\n",
    "\n",
    "def find_category_name(file_name):\n",
    "    if \"-\" in file_name:\n",
    "        parts = file_name.split(\"-\")\n",
    "        return parts[1] if len(parts) > 1 else file_name\n",
    "    else:\n",
    "        return file_name\n",
    "\n",
    "def extract_unique_file_id(file_name):\n",
    "    return file_name.rsplit('-', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns:\n",
    "df[\"category\"] = df[\"Category\"].apply(find_category)\n",
    "df[\"category_name\"] = df[\"Category\"].apply(find_category_name)\n",
    "df[\"unique_file_id\"] = df[\"Category\"].apply(extract_unique_file_id)\n",
    "\n",
    "# Compute unique file counts per malware family and create a summary DataFrame:\n",
    "unique_counts = df.groupby('category_name')['unique_file_id'].nunique()\n",
    "total_records = df['category_name'].value_counts()\n",
    "df_category_summary = pd.DataFrame({\n",
    "    'Total_Records': total_records,\n",
    "    'Unique_File_Counts': unique_counts\n",
    "})\n",
    "df_category_summary['Percentage'] = (df_category_summary['Total_Records'] / len(df)) * 100\n",
    "df_category_summary = df_category_summary.reset_index().rename(columns={'index': 'category_name'})\n",
    "df_category_summary.to_csv(\"df_category_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------PREPROCESSING & ENCODING--------------------------------------------------------\n",
    "meta_cols = ['Category', 'category_name', 'unique_file_id']\n",
    "df_meta = df[meta_cols].copy()\n",
    "\n",
    "le_class = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "le_catname = LabelEncoder()\n",
    "\n",
    "df['Class_encoded'] = le_class.fit_transform(df['Class'])\n",
    "df['category_encoded'] = le_category.fit_transform(df['category'])\n",
    "df['category_name_encoded'] = le_catname.fit_transform(df['category_name'])\n",
    "\n",
    "df['group_id'] = df.apply(lambda row: row['unique_file_id'] \n",
    "                                    if row['Class'] != 'Benign' \n",
    "                                    else f\"benign_{row.name}\", axis=1)\n",
    "\n",
    "# Drop columns used for meta or non-numeric:\n",
    "features = df.drop(columns=[\n",
    "    'Category', 'Class', 'category', 'category_name',\n",
    "    'Class_encoded', 'category_encoded', 'category_name_encoded',\n",
    "    'unique_file_id', 'group_id'\n",
    "])\n",
    "target = df['category_name_encoded']\n",
    "\n",
    "# ----------------------------------------------------------SPLITTING DATA--------------------------------------------------------------\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.35, random_state=42)\n",
    "train_idx, temp_idx = next(gss.split(df, groups=df['group_id']))\n",
    "train_df = df.iloc[train_idx]\n",
    "temp_df = df.iloc[temp_idx]\n",
    "\n",
    "gss_temp = GroupShuffleSplit(n_splits=1, test_size=0.857, random_state=42)\n",
    "val_idx, test_idx = next(gss_temp.split(temp_df, groups=temp_df['group_id']))\n",
    "validation_df = temp_df.iloc[val_idx]\n",
    "test_df = temp_df.iloc[test_idx]\n",
    "\n",
    "def get_features_and_target(sub_df):\n",
    "    X = sub_df.drop(columns=[\n",
    "        'Category', 'Class', 'category', 'category_name', \n",
    "        'Class_encoded', 'category_encoded', 'category_name_encoded',\n",
    "        'unique_file_id', 'group_id'\n",
    "    ])\n",
    "    y = sub_df['category_name_encoded']\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = get_features_and_target(train_df)\n",
    "X_val, y_val = get_features_and_target(validation_df)\n",
    "X_test, y_test = get_features_and_target(test_df)\n",
    "\n",
    "meta_val = validation_df[meta_cols].copy()\n",
    "meta_test = test_df[meta_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049aa481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------CLASSIFIERS & CONFIGURATION--------------------------------------------------\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=5, min_samples_split=4, \n",
    "    min_samples_leaf=2, random_state=42\n",
    ")\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "logistic_classifier = LogisticRegression(\n",
    "    penalty='l2', C=0.5, solver='liblinear', max_iter=1000, random_state=42\n",
    ")\n",
    "tree_classifier = DecisionTreeClassifier(\n",
    "    max_depth=5, min_samples_split=4, min_samples_leaf=2, random_state=42\n",
    ")\n",
    "svm_classifier = SVC(\n",
    "    kernel='rbf', C=0.5, gamma='scale', probability=True, random_state=42\n",
    ")\n",
    "\n",
    "# Classifier dictionary (model, scale_required):\n",
    "classifiers = {\n",
    "    'RandomForest': (rf_classifier, False),\n",
    "    'KNN': (knn_classifier, True),\n",
    "    'LogisticRegression': (logistic_classifier, True),\n",
    "    'DecisionTree': (tree_classifier, False),\n",
    "    'SVM': (svm_classifier, True)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids:\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 75],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [4, 6],\n",
    "        'min_samples_leaf': [2, 3]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [7, 9, 11]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 0.5, 1]\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'max_depth': [3, 5],\n",
    "        'min_samples_split': [6, 8],\n",
    "        'min_samples_leaf': [2, 3]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 0.5, 1],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "}\n",
    "\n",
    "results_dict = {}\n",
    "shap_values_dict = {}\n",
    "train_groups = train_df['group_id']\n",
    "\n",
    "# Encoded value for \"Conti\":\n",
    "conti_label = \"Conti\"\n",
    "conti_encoded = le_catname.transform([conti_label])[0]\n",
    "\n",
    "# Lists to collect evaluation metrics and SHAP features:\n",
    "metrics_list = []\n",
    "shap_features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------TRAINING, EVALUATION & SHAP--------------------------------------------------\n",
    "for clf_name, (clf_obj, scale_required) in classifiers.items():\n",
    "    #print(f\"\\nTraining and evaluating {clf_name}...\")\n",
    "\n",
    "    # Build pipeline:\n",
    "    if scale_required:\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', clf_obj)\n",
    "        ])\n",
    "        # GridSearchCV for relevant classifier:\n",
    "        if clf_name in param_grids:\n",
    "            grid = {f'clf__{param}': values for param, values in param_grids[clf_name].items()}\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline, grid, cv=GroupKFold(n_splits=5),\n",
    "                scoring='accuracy', n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train, groups=train_groups)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            #print(f\"Best parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "        else:\n",
    "            best_model = pipeline.fit(X_train, y_train)\n",
    "    else:\n",
    "        # No scaling:\n",
    "        if clf_name in param_grids:\n",
    "            grid_search = GridSearchCV(\n",
    "                clf_obj, param_grids[clf_name], cv=GroupKFold(n_splits=5),\n",
    "                scoring='accuracy', n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train, groups=train_groups)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            #print(f\"Best parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "        else:\n",
    "            best_model = clf_obj.fit(X_train, y_train)\n",
    "\n",
    "    # Ensure 'models' directory exists:\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "    # Save the trained model:\n",
    "    model_save_path = f\"../models/{clf_name}_trained_model.pkl\"\n",
    "    joblib.dump(best_model, model_save_path)\n",
    "    #print(f\"Saved {clf_name} model to {model_save_path}\")\n",
    "\n",
    "# -------------------------------------------------------Predictions & Metrics--------------------------------------------------------\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    y_val_pred_labels = le_catname.inverse_transform(y_val_pred)\n",
    "    y_val_labels = le_catname.inverse_transform(y_val)\n",
    "    y_test_pred_labels = le_catname.inverse_transform(y_test_pred)\n",
    "    y_test_labels = le_catname.inverse_transform(y_test)\n",
    "    \n",
    "    # Classification report for each class:\n",
    "    report_dict = classification_report(y_test_labels, y_test_pred_labels, output_dict=True)\n",
    "    for class_label, scores in report_dict.items():\n",
    "        if class_label not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "            metrics_list.append({\n",
    "                'Classifier': clf_name,\n",
    "                'Class': class_label,\n",
    "                'Precision': scores.get('precision', None),\n",
    "                'Recall': scores.get('recall', None),\n",
    "                'F1-score': scores.get('f1-score', None),\n",
    "                'Support': scores.get('support', None)\n",
    "            })\n",
    "    \n",
    "# -------------------------------------------------------SHAP Feature Importance for \"Conti\"------------------------------------------\n",
    "    try:\n",
    "        # If model is wrapped in pipeline, extract the final estimator\n",
    "        if scale_required:\n",
    "            model_for_shap = best_model.named_steps['clf']\n",
    "        else:\n",
    "            model_for_shap = best_model\n",
    "        \n",
    "        # Create a generic SHAP explainer:\n",
    "        explainer = shap.Explainer(model_for_shap, X_train, feature_names=X_train.columns)\n",
    "        shap_values = explainer(X_test)\n",
    "        \n",
    "        # Store the SHAP values for potential future plotting:\n",
    "        shap_values_dict[clf_name] = shap_values\n",
    "\n",
    "        # If multi-class, isolate the \"Conti\" class:\n",
    "        if len(shap_values.values.shape) == 3:\n",
    "            # shape: (n_samples, n_features, n_classes):\n",
    "            conti_shap = shap_values.values[:, :, conti_encoded]\n",
    "            mean_shap = np.abs(conti_shap).mean(axis=0)\n",
    "        else:\n",
    "            mean_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "        \n",
    "        shap_importance = pd.Series(mean_shap, index=X_test.columns).sort_values(ascending=False)\n",
    "        \n",
    "        #print(f\"\\nSHAP Feature Importance for '{conti_label}' - {clf_name}:\")\n",
    "        #print(shap_importance)\n",
    "        \n",
    "\n",
    "        # Plot a bar chart of all features:\n",
    "        feature_importance = shap_importance\n",
    "        feature_importance.plot(kind='bar', title=f\"SHAP Importance for '{conti_label}' - {clf_name}\")\n",
    "        plt.ylabel('Mean |SHAP value|')\n",
    "\n",
    "        # Save SHAP plot as image:\n",
    "        os.makedirs(\"../outputs/shap_charts\", exist_ok=True)\n",
    "        shap_chart_path = f\"../outputs/shap_charts/{clf_name}_SHAP_Importance.png\"\n",
    "        plt.savefig(shap_chart_path, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Collect all SHAP features for Excel output:\n",
    "        for feature, shap_val in feature_importance.items():\n",
    "            shap_features_list.append({\n",
    "                'Classifier': clf_name, \n",
    "                'Feature': feature, \n",
    "                'SHAP Importance': shap_val\n",
    "            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP explanation failed for {clf_name}: {e}\")\n",
    "    \n",
    "# -----------------------------------------------------------Save Test Results--------------------------------------------------------\n",
    "    if hasattr(best_model, \"predict_proba\"):\n",
    "        test_probs = best_model.predict_proba(X_test)\n",
    "        predicted_probabilities = [round(prob[label] * 100, 2)\n",
    "                                   for prob, label in zip(test_probs, y_test_pred)]\n",
    "    else:\n",
    "        predicted_probabilities = [None] * len(y_test)\n",
    "    \n",
    "    results_test_clf = X_test.copy()\n",
    "    results_test_clf['Actual_Class'] = y_test_labels\n",
    "    results_test_clf['Predicted_Class'] = y_test_pred_labels\n",
    "    results_test_clf['Correct'] = results_test_clf['Actual_Class'] == results_test_clf['Predicted_Class']\n",
    "    results_test_clf['Prediction_Probability'] = predicted_probabilities\n",
    "    results_test_clf = results_test_clf.merge(meta_test, left_index=True, right_index=True)\n",
    "    \n",
    "    csv_filename = f\"{clf_name}_Malware_Type_Test_Results.csv\"\n",
    "    results_test_clf.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    # Print Validation and Test Reports:\n",
    "    #print(f\"\\nValidation Set Classification Report for {clf_name}:\")\n",
    "    #print(classification_report(y_val_labels, y_val_pred_labels, digits=4))\n",
    "    #print(f\"\\nTest Set Classification Report for {clf_name}:\")\n",
    "    #print(classification_report(y_test_labels, y_test_pred_labels, digits=4))\n",
    "    results_dict[clf_name] = results_test_clf\n",
    "\n",
    "# -----------------------------------------------------------SAVE RESULTS TO EXCEL----------------------------------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "shap_features_df = pd.DataFrame(shap_features_list)\n",
    "\n",
    "with pd.ExcelWriter(\"Classifier_Results.xlsx\") as writer:\n",
    "    metrics_df.to_excel(writer, sheet_name=\"Metrics\", index=False)\n",
    "    shap_features_df.to_excel(writer, sheet_name=\"SHAP_Features\", index=False)\n",
    "    \n",
    "#print(\"\\nCombined classification metrics and SHAP feature importances saved to 'Classifier_Results.xlsx'.\")\n",
    "\n",
    "# Save the datasets:\n",
    "train_df.to_csv(\"Train_Dataset_Malware_Type.csv\", index=False)\n",
    "validation_df.to_csv(\"Validation_Dataset_Malware_Type.csv\", index=False)\n",
    "test_df.to_csv(\"Test_Dataset_Malware_Type.csv\", index=False)\n",
    "\n",
    "\n",
    "# Choose a classifier for SHAP visualization, change this for different models:\n",
    "clf_to_plot = \"RandomForest\"\n",
    "\n",
    "if clf_to_plot in shap_values_dict:\n",
    "    shap_values = shap_values_dict[clf_to_plot]\n",
    "\n",
    "    print(f\"\\nGenerating SHAP summary plot for {clf_to_plot}...\")\n",
    "\n",
    "    # Convert SHAP Explanation object to NumPy format:\n",
    "    if isinstance(shap_values, shap.Explanation):\n",
    "        shap_values_array = shap_values.values\n",
    "        feature_names = shap_values.feature_names\n",
    "    else:\n",
    "        shap_values_array = shap_values\n",
    "        feature_names = X_test.columns.tolist()\n",
    "\n",
    "    # Ensure SHAP values are 2D for summary plot:\n",
    "    if shap_values_array.ndim == 3:\n",
    "        shap_values_array = shap_values_array[:, :, 0]\n",
    "\n",
    "    # Convert X_test to NumPy for SHAP compatibility:\n",
    "    X_test_np = X_test.to_numpy()\n",
    "\n",
    "    # Add Title to the Plot:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f\"SHAP Summary Plot - {clf_to_plot} Model\", fontsize=14, fontweight=\"bold\")\n",
    "    shap.summary_plot(shap_values_array, X_test_np, feature_names=feature_names, show=False)\n",
    "    #plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"SHAP values not found for {clf_to_plot}. Ensure training completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
